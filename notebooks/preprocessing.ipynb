{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2340dcc",
   "metadata": {},
   "source": [
    "# PROBABILE STRUTTURA\n",
    "1. Caricamento dei file audio\n",
    "2. Parsing del filename → estrazione emotion_id\n",
    "3. Creazione DataFrame per vedere se tutto è corretto  ← QUI metti il codice\n",
    "4. Generazione dei mel-spectrogram\n",
    "5. Decisione dei parametri (n_mels, hop, win, durata, padding)\n",
    "6. Test di un paio di augmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f72ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\franc\\\\Politecnico Di Torino Studenti Dropbox\\\\Francesca Melloni\\\\POLITO\\\\2°anno, I semestre\\\\ML\\\\Project ML\\\\SER-Machine-Learning-Project\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e693d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale file: 1440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data\\Actor_01\\03-01-01-01-01-01-01.wav</td>\n",
       "      <td>01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data\\Actor_01\\03-01-01-01-01-02-01.wav</td>\n",
       "      <td>01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data\\Actor_01\\03-01-01-01-02-01-01.wav</td>\n",
       "      <td>01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data\\Actor_01\\03-01-01-01-02-02-01.wav</td>\n",
       "      <td>01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data\\Actor_01\\03-01-02-01-01-01-01.wav</td>\n",
       "      <td>02</td>\n",
       "      <td>calm</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filepath emotion_id emotion_label actor\n",
       "0  ../data\\Actor_01\\03-01-01-01-01-01-01.wav         01       neutral    01\n",
       "1  ../data\\Actor_01\\03-01-01-01-01-02-01.wav         01       neutral    01\n",
       "2  ../data\\Actor_01\\03-01-01-01-02-01-01.wav         01       neutral    01\n",
       "3  ../data\\Actor_01\\03-01-01-01-02-02-01.wav         01       neutral    01\n",
       "4  ../data\\Actor_01\\03-01-02-01-01-01-01.wav         02          calm    01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from preprocessing.dataset import extract_emotion_label, EMOTION_MAP\n",
    "\n",
    "audio_files = glob(\"../data/Actor_*/*.wav\", recursive=True)\n",
    "print(\"Numero totale file:\", len(audio_files))\n",
    "audio_files[:3]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for f in audio_files:\n",
    "    filename = os.path.basename(f)\n",
    "    parts = filename.split('-')\n",
    "\n",
    "    emotion_id = parts[2]\n",
    "    emotion_label = EMOTION_MAP[emotion_id]\n",
    "\n",
    "    actor = parts[-1].split('.')[0]  # ultimo numero prima del .wav\n",
    "\n",
    "    rows.append([f, emotion_id, emotion_label, actor])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"filepath\", \"emotion_id\", \"emotion_label\", \"actor\"])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET CHECK ===\n",
      "\n",
      "Totale file audio: 1440\n",
      "\n",
      "Distribuzione emozioni:\n",
      "emotion_label\n",
      "angry        192\n",
      "calm         192\n",
      "disgust      192\n",
      "fearful      192\n",
      "happy        192\n",
      "neutral       96\n",
      "sad          192\n",
      "surprised    192\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Distribuzione attori:\n",
      "actor\n",
      "01    60\n",
      "02    60\n",
      "03    60\n",
      "04    60\n",
      "05    60\n",
      "06    60\n",
      "07    60\n",
      "08    60\n",
      "09    60\n",
      "10    60\n",
      "11    60\n",
      "12    60\n",
      "13    60\n",
      "14    60\n",
      "15    60\n",
      "16    60\n",
      "17    60\n",
      "18    60\n",
      "19    60\n",
      "20    60\n",
      "21    60\n",
      "22    60\n",
      "23    60\n",
      "24    60\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "✔ Nessun valore mancante nel dataset\n"
     ]
    }
   ],
   "source": [
    "# Verifica della corretta popolazione del dataset\n",
    "\n",
    "print(\"=== DATASET CHECK ===\\n\")\n",
    "\n",
    "print(f\"Totale file audio: {len(df)}\\n\")\n",
    "\n",
    "print(\"Distribuzione emozioni:\")\n",
    "print(df[\"emotion_label\"].value_counts().sort_index(), \"\\n\")\n",
    "\n",
    "print(\"Distribuzione attori:\")\n",
    "print(df[\"actor\"].value_counts().sort_index(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfbba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 64\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 160      # ~10 ms\n",
    "WIN_LENGTH = 400      # ~25 ms\n",
    "MAX_DURATION = 4.0    # secondi\n",
    "MAX_SAMPLES = int(SAMPLE_RATE * MAX_DURATION)\n",
    "\n",
    "# 1. CARICAMENTO AUDIO\n",
    "audio_path = audio_files[0]  # prendiamo un file qualsiasi per test\n",
    "\n",
    "# Carica audio e ricampiona a 16 kHz\n",
    "waveform, sr = torchaudio.load(audio_path)\n",
    "\n",
    "# (solo mono perchè non ci servono informazioni stereo che servono per spazialità e ambienti)\n",
    "# Carica audio (torna: waveform [channels, samples], sample_rate)\n",
    "if waveform.shape[0] > 1:\n",
    "    waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "# Ricampionamento a 16 kHz\n",
    "if sr != SAMPLE_RATE:\n",
    "    resampler = T.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "    waveform = resampler(waveform)\n",
    "\n",
    "# 2. PAD / CROP A DURATA FISSA\n",
    "num_samples = waveform.shape[1]\n",
    "\n",
    "if num_samples < MAX_SAMPLES:\n",
    "    # padding con zeri\n",
    "    padding = MAX_SAMPLES - num_samples\n",
    "    waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "else:\n",
    "    # crop\n",
    "    waveform = waveform[:, :MAX_SAMPLES]\n",
    "\n",
    "# 3. MEL-SPECTROGRAM\n",
    "mel_transform = T.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    win_length=WIN_LENGTH,\n",
    "    n_mels=N_MELS,\n",
    "    power=2.0  # spettrogramma di potenza\n",
    ")\n",
    "\n",
    "mel_spec = mel_transform(waveform)  # shape: [1, n_mels, time]\n",
    "\n",
    "# 4. LOG-MEL\n",
    "log_mel_spec = torch.log(mel_spec + 1e-9)\n",
    "\n",
    "# 5. NORMALIZZAZIONE (per sample)\n",
    "mean = log_mel_spec.mean()\n",
    "std = log_mel_spec.std()\n",
    "log_mel_spec = (log_mel_spec - mean) / std\n",
    "\n",
    "# 6. VERIFICA SHAPE E VALORI\n",
    "print(\"Shape log-mel:\", log_mel_spec.shape)\n",
    "print(\"Min:\", log_mel_spec.min().item())\n",
    "print(\"Max:\", log_mel_spec.max().item())\n",
    "print(\"Mean:\", log_mel_spec.mean().item())\n",
    "print(\"Std:\", log_mel_spec.std().item())\n",
    "\n",
    "# 7. VISUALIZZAZIONE\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(\n",
    "    log_mel_spec.squeeze(0).numpy(),\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\"\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Log-Mel Spectrogram (normalizzato)\")\n",
    "plt.xlabel(\"Time frames\")\n",
    "plt.ylabel(\"Mel bins\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
