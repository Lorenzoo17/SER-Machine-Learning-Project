{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2340dcc",
   "metadata": {},
   "source": [
    "# PROBABILE STRUTTURA\n",
    "1. Caricamento dei file audio\n",
    "2. Parsing del filename → estrazione emotion_id\n",
    "3. Creazione DataFrame per vedere se tutto è corretto  ← QUI metti il codice\n",
    "4. Generazione dei mel-spectrogram\n",
    "5. Decisione dei parametri (n_mels, hop, win, durata, padding)\n",
    "6. Test di un paio di augmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f72ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/franc/AppData/Local/Programs/Python/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from preprocessing.dataset import extract_emotion_label, EMOTION_MAP\n",
    "\n",
    "audio_files = glob(\"../data/Actor_*/*.wav\", recursive=True)\n",
    "print(\"Numero totale file:\", len(audio_files))\n",
    "audio_files[:3]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for f in audio_files:\n",
    "    filename = os.path.basename(f)\n",
    "    parts = filename.split('-')\n",
    "\n",
    "    emotion_id = parts[2]\n",
    "    emotion_label = EMOTION_MAP[emotion_id]\n",
    "\n",
    "    actor = parts[-1].split('.')[0]  # ultimo numero prima del .wav\n",
    "\n",
    "    rows.append([f, emotion_id, emotion_label, actor])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"filepath\", \"emotion_id\", \"emotion_label\", \"actor\"])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica della corretta popolazione del dataset\n",
    "\n",
    "print(\"=== DATASET CHECK ===\\n\")\n",
    "\n",
    "print(f\"Totale file audio: {len(df)}\\n\")\n",
    "\n",
    "print(\"Distribuzione emozioni:\")\n",
    "print(df[\"emotion_label\"].value_counts().sort_index(), \"\\n\")\n",
    "\n",
    "print(\"Distribuzione attori:\")\n",
    "print(df[\"actor\"].value_counts().sort_index(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se da errore con torchaudio\n",
    "# !pip install torch torchaudio\n",
    "# !pip install torchcodec\n",
    "# !pip install soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfbba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 64\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 160      # ~10 ms\n",
    "WIN_LENGTH = 400      # ~25 ms\n",
    "MAX_DURATION = 4.0    # secondi\n",
    "MAX_SAMPLES = int(SAMPLE_RATE * MAX_DURATION)\n",
    "\n",
    "# 1. CARICAMENTO AUDIO\n",
    "audio_path = audio_files[0]  # prendiamo un file qualsiasi per test\n",
    "\n",
    "# Carica audio e ricampiona a 16 kHz\n",
    "audio, sr = sf.read(audio_path, dtype=\"float32\")\n",
    "\n",
    "# (solo mono perchè non ci servono informazioni stereo che servono per spazialità e ambienti)\n",
    "# Carica audio (torna: waveform [channels, samples], sample_rate)\n",
    "if audio.ndim > 1:\n",
    "    audio = audio.mean(axis=1)\n",
    "\n",
    "waveform = torch.from_numpy(audio).float().unsqueeze(0)\n",
    "# Ricampionamento a 16 kHz\n",
    "if sr != SAMPLE_RATE:\n",
    "    resampler = T.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "    waveform = resampler(waveform)\n",
    "\n",
    "# 2. PAD / CROP A DURATA FISSA\n",
    "num_samples = waveform.shape[1]\n",
    "\n",
    "if num_samples < MAX_SAMPLES:\n",
    "    # padding con zeri\n",
    "    padding = MAX_SAMPLES - num_samples\n",
    "    waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "else:\n",
    "    # crop\n",
    "    waveform = waveform[:, :MAX_SAMPLES]\n",
    "\n",
    "# 3. MEL-SPECTROGRAM\n",
    "mel_transform = T.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    win_length=WIN_LENGTH,\n",
    "    n_mels=N_MELS,\n",
    "    power=2.0  # spettrogramma di potenza\n",
    ")\n",
    "\n",
    "mel_spec = mel_transform(waveform)  # shape: [1, n_mels, time]\n",
    "\n",
    "# 4. LOG-MEL\n",
    "log_mel_spec = torch.log(mel_spec + 1e-9)\n",
    "\n",
    "# 5. NORMALIZZAZIONE (per sample)\n",
    "mean = log_mel_spec.mean()\n",
    "std = log_mel_spec.std()\n",
    "log_mel_spec = (log_mel_spec - mean) / (std + 1e-9)  # evito divisione per 0\n",
    "\n",
    "# 6. VERIFICA SHAPE E VALORI\n",
    "print(\"Shape log-mel:\", log_mel_spec.shape)\n",
    "print(\"Min:\", log_mel_spec.min().item())\n",
    "print(\"Max:\", log_mel_spec.max().item())\n",
    "print(\"Mean:\", log_mel_spec.mean().item())\n",
    "print(\"Std:\", log_mel_spec.std().item())\n",
    "\n",
    "# 7. VISUALIZZAZIONE\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(\n",
    "    log_mel_spec.squeeze(0).numpy(),\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\"\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Log-Mel Spectrogram (normalizzato)\")\n",
    "plt.xlabel(\"Time frames\")\n",
    "plt.ylabel(\"Mel bins\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
